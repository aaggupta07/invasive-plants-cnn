{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# For saving images\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Metrics\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get all the images from their urls, resize them, and save them locally\n",
    "folder = \"all-plant-data\"\n",
    "new_folder = \"plant-images-64\"\n",
    "temp = os.path.join(new_folder, \"temp\")\n",
    "rescale = 64\n",
    "start = False\n",
    "files = os.listdir(folder)\n",
    "\n",
    "for file in tqdm(files, desc='Plants Completed: '):\n",
    "    df = pd.read_csv(os.path.join(folder, file))\n",
    "    plant = str(file)[:-4]\n",
    "\n",
    "    for idx, url in enumerate(tqdm(df['image_url'], desc=f'{plant}: ')):\n",
    "        attempts = 0\n",
    "\n",
    "        while attempts < 5:\n",
    "            try:\n",
    "                filepath = os.path.join(new_folder, plant, str(idx))\n",
    "\n",
    "                r = requests.get(url, stream=True)\n",
    "                r.raw_decode_content = True\n",
    "\n",
    "                with open(temp, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(r.raw, f_out)\n",
    "\n",
    "                image = Image.open(temp)\n",
    "                image = image.resize((rescale, rescale))\n",
    "                image.save(str(filepath) + \".png\")\n",
    "\n",
    "                if attempts > 0:\n",
    "                    print(f\"Succeeded after {attempts + 1} tries\")\n",
    "                break\n",
    "\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print(f\"ConnectionError: Could not get image {idx} of file {file}\")\n",
    "                if attempts < 4: print(\"Attempting to retry...\")\n",
    "                else: print(\"Failed 5 times, moving on to next image\")\n",
    "                attempts += 1\n",
    "\n",
    "# Time Taken to download all 69,850 images: 6:51:48"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_native = set()\n",
    "for file in os.listdir('native-plant-data'):\n",
    "    is_native.add(str(file)[:-4])\n",
    "\n",
    "subset_native = set()\n",
    "\n",
    "for idx, file in enumerate(os.listdir('plant-images')):\n",
    "    if str(file) in is_native: subset_native.add(idx)\n",
    "\n",
    "print(subset_native)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transfer Learning with ResNet50\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, lr, tol, batch_size, epochs, num_classes):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "\n",
    "        # Initialization\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # For plotting\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.epoch_acc_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.val_acc_history = []\n",
    "\n",
    "        self.test_acc = -1\n",
    "        self.test_loss = -1\n",
    "        self.sub_acc = -1\n",
    "\n",
    "        # Model\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT, download=True).to(self.device)\n",
    "\n",
    "        self.in_dims = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features=self.in_dims, out_features=self.num_classes)\n",
    "\n",
    "        # Optimizer and loss function\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr = self.lr)\n",
    "\n",
    "        # Move model to the GPU and get data\n",
    "        self.to(self.device)\n",
    "\n",
    "        self.train_data_loader = None\n",
    "        self.val_data_loader = None\n",
    "        self.test_data_loader = None\n",
    "        self.get_data()\n",
    "\n",
    "\n",
    "    # Forward pass for the model\n",
    "    def forward(self, batch_data):\n",
    "        batch_data = batch_data.clone().detach().to(self.device)\n",
    "        out = self.model(batch_data)\n",
    "        return out\n",
    "\n",
    "\n",
    "    # Get data to train the model\n",
    "    def get_data(self):\n",
    "        # Data augmentation\n",
    "        tf = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "\n",
    "        invasive_data = datasets.ImageFolder('plant-images', transform=tf)\n",
    "\n",
    "        train_data, val_data, test_data = random_split(invasive_data, [0.7, 0.15, 0.15], generator=torch.Generator().manual_seed(61))\n",
    "\n",
    "        self.train_data_loader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        self.val_data_loader = DataLoader(val_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        self.test_data_loader = DataLoader(test_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    def train_(self):\n",
    "        stop = False\n",
    "        time_started = time.time()\n",
    "\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "        best_loss = 10000000.0\n",
    "        best_acc = 0\n",
    "        past = 0\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            header = f\"Epoch {i+1}/{self.epochs}\"\n",
    "            print(header)\n",
    "            print(\"-\" * len(header))\n",
    "\n",
    "            loader = self.train_data_loader\n",
    "            for phase in ['train', 'validate']:\n",
    "                if phase == 'train':\n",
    "                    self.train()\n",
    "                else:\n",
    "                    self.eval()\n",
    "                    loader = self.val_data_loader\n",
    "\n",
    "                # For plotting and statistics\n",
    "                epoch_loss = 0\n",
    "                epoch_acc = []\n",
    "\n",
    "                # Main training loop\n",
    "                for in_data, label in loader:\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # Get model prediction and determine how well it did\n",
    "                    label = label.to(self.device)\n",
    "                    prediction = self.forward(in_data)\n",
    "                    classes = torch.argmax(prediction, dim=1)\n",
    "\n",
    "                    wrong = torch.where(torch.tensor(classes != label).to(self.device),\n",
    "                                        torch.tensor([1.]).to(self.device),\n",
    "                                        torch.tensor([0.]).to(self.device))\n",
    "\n",
    "                    # Calculate loss and accuracy\n",
    "                    acc = 1 - torch.sum(wrong) / self.batch_size\n",
    "                    batch_loss = self.loss(prediction, label)\n",
    "                    epoch_loss += batch_loss.item()\n",
    "                    epoch_acc.append(acc.item())\n",
    "\n",
    "                    # Train through backpropagation\n",
    "                    if phase == 'train':\n",
    "                        batch_loss.backward()\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                        # Statistics\n",
    "                        self.acc_history.append(acc.item())\n",
    "\n",
    "\n",
    "                elapsed = time.time() - time_started\n",
    "                print(f\"Finished {phase} with loss {epoch_loss} and accuracy of {np.mean(epoch_acc)} in time \"\n",
    "                      f\"{int((elapsed // 60) // 60)}:{int(elapsed // 60)}:{int(elapsed % 60)}\")\n",
    "\n",
    "                if phase == 'train':\n",
    "                    self.loss_history.append(epoch_loss)\n",
    "                    self.epoch_acc_history.append(np.mean(epoch_acc))\n",
    "                else:\n",
    "                    self.val_loss_history.append(epoch_loss)\n",
    "                    self.val_acc_history.append(np.mean(epoch_acc))\n",
    "                    best_acc = max(best_acc, np.mean(epoch_acc).item())\n",
    "\n",
    "                    if (best_loss - epoch_loss > 0.03 * best_loss and best_loss - epoch_loss > 4) or (best_loss - epoch_loss >= 50):\n",
    "                        past = 0\n",
    "                        best_loss = epoch_loss\n",
    "                        best_model = copy.deepcopy(model.state_dict())\n",
    "                    else:\n",
    "                        past += 1\n",
    "                        print(\"No improvement over last epoch.\")\n",
    "                        if past >= self.tol:\n",
    "                            print(\"No improvement in model loss. Early stopping...\")\n",
    "                            stop = True\n",
    "                            break\n",
    "\n",
    "            print()\n",
    "            if stop: break\n",
    "\n",
    "        print(\"Training complete...\")\n",
    "        print(f\"Best validation loss: {best_loss}\")\n",
    "        print(f\"Best validation accuracy: {best_acc}\")\n",
    "\n",
    "        model.load_state_dict(best_model)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def test_(self):\n",
    "        self.eval()\n",
    "\n",
    "        time_started = time.time()\n",
    "        total_loss = 0\n",
    "        total_acc = []\n",
    "        total_sub_acc = []\n",
    "\n",
    "        for in_data, label in self.test_data_loader:\n",
    "\n",
    "            # Compare correct answers to model\n",
    "            label = label.to(self.device)\n",
    "            prediction = self.forward(in_data)\n",
    "            classes = torch.argmax(prediction, dim=1)\n",
    "\n",
    "            wrong = torch.where(torch.tensor(classes != label).to(self.device),\n",
    "                                torch.tensor([1.]).to(self.device),\n",
    "                                torch.tensor([0.]).to(self.device))\n",
    "\n",
    "            wrong_sub = 0\n",
    "            for i in range(len(classes)):\n",
    "                if (classes[i].item() in subset_native) != (label[i].item() in subset_native): wrong_sub += 1\n",
    "\n",
    "\n",
    "            acc = 1 - torch.sum(wrong) / self.batch_size\n",
    "            sub_acc = 1 - wrong_sub / self.batch_size\n",
    "            batch_loss = self.loss(prediction, label)\n",
    "\n",
    "            total_acc.append(acc.item())\n",
    "            total_sub_acc.append(sub_acc)\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "        self.test_acc = np.mean(total_acc)\n",
    "        self.test_loss = total_loss\n",
    "        self.sub_acc = np.mean(total_sub_acc)\n",
    "        elapsed = time.time() - time_started\n",
    "        print(f\"Finished with loss {total_loss} and accuracy of {np.mean(total_acc)} in {int(elapsed // 60)}:{int(elapsed % 60)}\")\n",
    "        print(f\"Testing Subset Accuracy (Invasive/Native): {model.sub_acc}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ResNetClassifier(lr=0.001, tol=2, batch_size=32, epochs=10, num_classes=23)\n",
    "model = model.train_()\n",
    "model.test_()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model-v4')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v = input(\"Enter version #: \")\n",
    "fig = int(input(\"Enter figure #: \"))\n",
    "epoch_dims = np.arange(1, len(model.loss_history) + 1, 1)\n",
    "path = 'graphs-analysis/'\n",
    "\n",
    "# Graph 1\n",
    "plt.plot(model.loss_history, marker='o', color='darkolivegreen')\n",
    "plt.title(f\"Figure {fig}: Cross-Entropy Training Loss vs. Number of Epochs\\nfor Version {v} of the Neural Network\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Training Loss\")\n",
    "plt.xticks(np.arange(len(model.loss_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-train-loss-graph.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Graph 2\n",
    "plt.plot(model.val_loss_history, marker='o', color='darkolivegreen')\n",
    "plt.title(\n",
    "    f\"Figure {fig + 1}: Cross-Entropy Validation Loss vs. Number of Epochs\\nfor Version {v} of the Neural Network\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Cross-Entropy Validation Loss\")\n",
    "plt.xticks(np.arange(len(model.val_loss_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-val-loss-graph.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Graph 3\n",
    "plt.plot(model.epoch_acc_history, marker='o', color='darkolivegreen')\n",
    "plt.title(f\"Figure {fig + 2}: Training Accuracy vs. Number of Epochs\\nfor Version {v} of the Neural Network\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy (Fraction)\")\n",
    "plt.xticks(np.arange(len(model.epoch_acc_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-epoch-acc-graph.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Graph 4\n",
    "plt.plot(model.val_acc_history, marker='o', color='darkolivegreen')\n",
    "plt.title(f\"Figure {fig + 3}: Validation Accuracy vs. Number of Epochs\\nfor Version {v} of the Neural Network\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy (Fraction)\")\n",
    "plt.xticks(np.arange(len(model.val_acc_history)), epoch_dims)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(path + 'v' + v + \"-val-acc-graph.png\", bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_to(fw, arr, header):\n",
    "    fw.write(header + '\\n[' + str(arr[0]))\n",
    "    for num in range(1, len(arr)):\n",
    "        fw.write(', ' + str(arr[num]))\n",
    "    fw.write(']\\n\\n')\n",
    "\n",
    "\n",
    "try: v\n",
    "except NameError: v = input(\"Enter version: \")\n",
    "\n",
    "with open(f'graphs-analysis/v{v}-data.txt', 'w') as f_out:\n",
    "    write_to(f_out, model.loss_history, \"Training Loss\")\n",
    "    write_to(f_out, model.val_loss_history, \"Validation Loss\")\n",
    "    write_to(f_out, model.epoch_acc_history, \"Training Accuracy (Per Epoch)\")\n",
    "    write_to(f_out, model.val_acc_history, \"Validation Accuracy\")\n",
    "\n",
    "    f_out.write(f\"Testing Loss, Accuracy\\n{model.test_loss}, {model.test_acc}\\n\\n\")\n",
    "\n",
    "    write_to(f_out, model.acc_history, \"Training Accuracy (Per Batch)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
